{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOefZI7cn8bV30xoKSczpDP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e1e0af21d0d44b99afeae0b9a4ec14d": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_178196dc27624a63a67931f3c072364d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[32m▰▰▱▱▱▱▱\u001b[0m Thinking...\n\u001b[36m┏━\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[36m━┓\u001b[0m\n\u001b[36m┃\u001b[0m                                                                                                                 \u001b[36m┃\u001b[0m\n\u001b[36m┃\u001b[0m \u001b[32mlightning attention by Minimax \u001b[0m                                                                                 \u001b[36m┃\u001b[0m\n\u001b[36m┃\u001b[0m                                                                                                                 \u001b[36m┃\u001b[0m\n\u001b[36m┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\u001b[0m\n\u001b[34m┏━\u001b[0m\u001b[34m Response (22.1s) \u001b[0m\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[34m━┓\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m • \u001b[0mRunning: duckduckgo_search(query=lightning attention by Minimax, max_results=5.0)                            \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m Running:                                                                                                        \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m • \u001b[0mread_article(url=https://arxiv.org/abs/2501.08313)                                                           \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m • \u001b[0mread_article(url=https://github.com/MiniMax-AI/MiniMax-01)                                                   \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m • \u001b[0mread_article(url=https://filecdn.minimax.chat/_Arxiv_MiniMax_01_Report.pdf)                                  \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m • \u001b[0mread_article(url=...)                                                                                        \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m • \u001b[0mread_article(url=https://www.youtube.com/watch?v=WmN6Rt_mHis)                                                \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m ┃                              \u001b[1mMiniMax-01: A Giant Leap in Large Language Models\u001b[0m                              ┃ \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛ \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m MiniMax has unveiled its groundbreaking MiniMax-01 series of large language models (LLMs), pushing the          \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m boundaries of what's possible in AI.  This series, including the text-focused MiniMax-Text-01 and the           \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m multimodal MiniMax-VL-01, boasts unprecedented capabilities, particularly in handling exceptionally long        \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m contexts.  This achievement is primarily attributed to the innovative implementation of \u001b[3mLightning Attention\u001b[0m.    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1mLightning Attention: The Key to Efficiency\u001b[0m                                                                      \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m The core innovation behind MiniMax-01 is its use of Lightning Attention.  Traditional attention mechanisms in   \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m LLMs exhibit quadratic complexity, meaning computational demands grow rapidly with increasing input length.     \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m Lightning Attention, however, achieves near-linear complexity, allowing the models to process millions of       \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m tokens efficiently.  This is a significant breakthrough, enabling the processing of vastly longer contexts than \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m previously possible with comparable models.  MiniMax-01 achieves this by using a hybrid approach; combining     \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m linear Lightning Attention with traditional SoftMax attention for optimal performance.                          \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1mScale and Performance\u001b[0m                                                                                           \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m MiniMax-Text-01 is a behemoth, with a staggering 456 billion parameters, though only 45.9 billion are activated \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m per token. This hybrid architecture, coupled with parallel processing strategies like Linear Attention Sequence \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m Parallelism Plus (LASP+), enables training with a context length of 1 million tokens and inference with up to 4 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m million.  Benchmark results show MiniMax-Text-01 outperforms leading models like GPT-4o and Claude-3.5-Sonnet   \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m across various tasks, especially those demanding long-context understanding.                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m MiniMax-VL-01, built upon MiniMax-Text-01, extends these capabilities to the visual domain.  Utilizing a        \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \"ViT-MLP-LLM\" framework, it integrates a Vision Transformer for visual encoding and leverages the power of      \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m MiniMax-Text-01 for language processing.  Its dynamic resolution mechanism further enhances its adaptability to \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m diverse visual inputs.  Benchmark results indicate top-tier performance on multimodal tasks, showcasing its     \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m proficiency in complex, multi-modal scenarios.                                                                  \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1mOpen-Source and Commercial Viability\u001b[0m                                                                            \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m MiniMax's commitment to open-sourcing the MiniMax-01 series is a significant development for the AI community.  \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m This move democratizes access to cutting-edge LLM technology and fosters further innovation.  However, MiniMax  \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m is also making the models commercially available through its API platform, offering a compelling solution for   \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m businesses seeking advanced AI capabilities.                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1mConclusion\u001b[0m                                                                                                      \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m MiniMax-01 represents a substantial advancement in the field of large language models. The innovative use of    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m Lightning Attention, combined with impressive scale and performance, positions MiniMax as a leader in the next  \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m generation of AI.  The open-source nature of the project further underscores its potential to reshape the       \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m future of AI development and application.  The commercial availability also shows a viable path for companies   \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m to harness its power.  The ongoing research and development surrounding this technology will undoubtedly have a \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m profound impact across various sectors, particularly those relying on natural language understanding and        \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m processing of vast amounts of information.                                                                      \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">▰▰▱▱▱▱▱</span> Thinking...\n<span style=\"color: #008080; text-decoration-color: #008080\">┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┃</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">┃</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┃</span> <span style=\"color: #008000; text-decoration-color: #008000\">lightning attention by Minimax </span>                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">┃</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┃</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">┃</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┏━ Response (22.1s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Running: duckduckgo_search(query=lightning attention by Minimax, max_results=5.0)                            <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> Running:                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>read_article(url=https://arxiv.org/abs/2501.08313)                                                           <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>read_article(url=https://github.com/MiniMax-AI/MiniMax-01)                                                   <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>read_article(url=https://filecdn.minimax.chat/_Arxiv_MiniMax_01_Report.pdf)                                  <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>read_article(url=...)                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>read_article(url=https://www.youtube.com/watch?v=WmN6Rt_mHis)                                                <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> ┃                              <span style=\"font-weight: bold\">MiniMax-01: A Giant Leap in Large Language Models</span>                              ┃ <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛ <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> MiniMax has unveiled its groundbreaking MiniMax-01 series of large language models (LLMs), pushing the          <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> boundaries of what's possible in AI.  This series, including the text-focused MiniMax-Text-01 and the           <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> multimodal MiniMax-VL-01, boasts unprecedented capabilities, particularly in handling exceptionally long        <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> contexts.  This achievement is primarily attributed to the innovative implementation of <span style=\"font-style: italic\">Lightning Attention</span>.    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"font-weight: bold\">Lightning Attention: The Key to Efficiency</span>                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> The core innovation behind MiniMax-01 is its use of Lightning Attention.  Traditional attention mechanisms in   <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> LLMs exhibit quadratic complexity, meaning computational demands grow rapidly with increasing input length.     <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> Lightning Attention, however, achieves near-linear complexity, allowing the models to process millions of       <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> tokens efficiently.  This is a significant breakthrough, enabling the processing of vastly longer contexts than <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> previously possible with comparable models.  MiniMax-01 achieves this by using a hybrid approach; combining     <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> linear Lightning Attention with traditional SoftMax attention for optimal performance.                          <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"font-weight: bold\">Scale and Performance</span>                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> MiniMax-Text-01 is a behemoth, with a staggering 456 billion parameters, though only 45.9 billion are activated <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> per token. This hybrid architecture, coupled with parallel processing strategies like Linear Attention Sequence <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> Parallelism Plus (LASP+), enables training with a context length of 1 million tokens and inference with up to 4 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> million.  Benchmark results show MiniMax-Text-01 outperforms leading models like GPT-4o and Claude-3.5-Sonnet   <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> across various tasks, especially those demanding long-context understanding.                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> MiniMax-VL-01, built upon MiniMax-Text-01, extends these capabilities to the visual domain.  Utilizing a        <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> \"ViT-MLP-LLM\" framework, it integrates a Vision Transformer for visual encoding and leverages the power of      <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> MiniMax-Text-01 for language processing.  Its dynamic resolution mechanism further enhances its adaptability to <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> diverse visual inputs.  Benchmark results indicate top-tier performance on multimodal tasks, showcasing its     <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> proficiency in complex, multi-modal scenarios.                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"font-weight: bold\">Open-Source and Commercial Viability</span>                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> MiniMax's commitment to open-sourcing the MiniMax-01 series is a significant development for the AI community.  <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> This move democratizes access to cutting-edge LLM technology and fosters further innovation.  However, MiniMax  <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> is also making the models commercially available through its API platform, offering a compelling solution for   <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> businesses seeking advanced AI capabilities.                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"font-weight: bold\">Conclusion</span>                                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> MiniMax-01 represents a substantial advancement in the field of large language models. The innovative use of    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> Lightning Attention, combined with impressive scale and performance, positions MiniMax as a leader in the next  <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> generation of AI.  The open-source nature of the project further underscores its potential to reshape the       <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> future of AI development and application.  The commercial availability also shows a viable path for companies   <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> to harness its power.  The ongoing research and development surrounding this technology will undoubtedly have a <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> profound impact across various sectors, particularly those relying on natural language understanding and        <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> processing of vast amounts of information.                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "178196dc27624a63a67931f3c072364d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rizwankaka/Agentic-AI-/blob/main/Datafy_Workshop/Phidata/phidata_research_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU google-generativeai duckduckgo-search newspaper4k lxml_html_clean phidata"
      ],
      "metadata": {
        "id": "5dL_X-5sV7zj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "J95ITMfOWjry"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1e1e0af21d0d44b99afeae0b9a4ec14d",
            "178196dc27624a63a67931f3c072364d"
          ]
        },
        "id": "hJsbtjkXV3tI",
        "outputId": "e5078af4-e36b-498a-e6b9-41b0978a1170"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e1e0af21d0d44b99afeae0b9a4ec14d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[33mWARNING \u001b[0m Error reading article from \u001b[4;94mhttps://filecdn.minimax.chat/_Arxiv_MiniMax_01_Report.pdf:\u001b[0m Article is binary   \n",
              "         data: \u001b[4;94mhttps://filecdn.minimax.chat/_Arxiv_MiniMax_01_Report.pdf\u001b[0m                                           \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> Error reading article from <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://filecdn.minimax.chat/_Arxiv_MiniMax_01_Report.pdf:</span> Article is binary   \n",
              "         data: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://filecdn.minimax.chat/_Arxiv_MiniMax_01_Report.pdf</span>                                           \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from phi.agent import Agent\n",
        "from phi.model.google import Gemini\n",
        "from phi.tools.duckduckgo import DuckDuckGo\n",
        "from phi.tools.newspaper4k import Newspaper4k\n",
        "\n",
        "agent = Agent(\n",
        "     model=Gemini(id=\"gemini-1.5-flash\"),\n",
        "    tools=[DuckDuckGo(), Newspaper4k()],\n",
        "    description=\"You are a senior NYT researcher writing an article on a topic.\",\n",
        "    instructions=[\n",
        "        \"For a given topic, search for the top 5 links.\",\n",
        "        \"Then read each URL and extract the article text, if a URL isn't available, ignore it.\",\n",
        "        \"Analyse and prepare an NYT worthy article based on the information.\",\n",
        "    ],\n",
        "    markdown=True,\n",
        "    show_tool_calls=True,\n",
        "    add_datetime_to_instructions=True,\n",
        "    # debug_mode=True,\n",
        ")\n",
        "agent.print_response(\"lightning attention by Minimax \", stream=True)\n",
        "\n"
      ]
    }
  ]
}